{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones a llamar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_dag(dag):\n",
    "    \"\"\"\n",
    "    Grafica el DAG de manera estructurada con pygraphviz.\n",
    "    \"\"\"\n",
    "    # Crear un grafo de pygraphviz\n",
    "    ag = nx.nx_agraph.to_agraph(dag)\n",
    "\n",
    "    # Etiquetar nodos con el schemaId\n",
    "    for node in dag.nodes:\n",
    "        ag.get_node(node).attr['label'] = dag.nodes[node]['schemaId']\n",
    "\n",
    "    # Configurar dirección del flujo\n",
    "    ag.graph_attr.update(rankdir='LR', splines='true', overlap='false')\n",
    "\n",
    "    # Dibujar el grafo\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ag.draw('/tmp/dag_output.png', prog='dot')  # Usa dot para una disposición estructurada\n",
    "    img = plt.imread('/tmp/dag_output.png')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## Funciones de bloques de Safe:\n",
    "def alarm_manager(inputs):\n",
    "    alarm_selection = inputs[\"alarm-selection\"]\n",
    "    print(f'ejecutado alarm_manager con alarma: {alarm_selection}')\n",
    "    return f\"Output of alarm_manager with alarm={alarm_selection}\"\n",
    "\n",
    "\n",
    "def notification_on_site(inputs):\n",
    "    notification_type = inputs.get(\"notification-type\", \"default\")\n",
    "    print(f'ejecutado notification_on_site con tipo: {notification_type}')\n",
    "    return f\"Output of notification_on_site with type={notification_type}\"\n",
    "\n",
    "def filter_node(inputs):\n",
    "    input_detections = inputs[\"input-detections\"]\n",
    "    filter_type = inputs[\"input-filter-type\"]\n",
    "    operator = inputs[\"input-operator\"]\n",
    "    value = inputs[\"input-value\"]\n",
    "    \n",
    "    print(f'ejecutado filter_node con tipo: {filter_type}, operador: {operator}, valor: {value}')\n",
    "    dets_true = []\n",
    "    dets_false = []\n",
    "    for det in input_detections:\n",
    "        if det['object'] == value:  # Asumiendo que queremos filtrar por tipo de objeto\n",
    "            dets_true.append(det)\n",
    "        else:\n",
    "            dets_false.append(det)\n",
    "    return {\"output-filtered-detections-pass\": dets_true, \"output-filtered-detections-fail\": dets_false}\n",
    "\n",
    "def ai_node(inputs):\n",
    "    \"\"\"\n",
    "    aqui pediria detecciones a la api para una camara dada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open('fake_dets/dets_response.json', 'r') as f:\n",
    "            detections_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Could not find detections file\")\n",
    "        return {\"camera_detections\": []}\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON format in detections file\")\n",
    "        return {\"camera_detections\": []}\n",
    "    \n",
    "    camera_name = inputs[\"camera-name\"]\n",
    "    print(f'ejecutado ai_node para camara: {camera_name}')\n",
    "    try:\n",
    "        return {\"camera_detections\": detections_dict['detections']['cameras'][camera_name]}\n",
    "    except KeyError:\n",
    "        print(f'No hay camara con nombre {camera_name}')\n",
    "        return {\"camera_detections\": []}\n",
    "\n",
    "def count_node(inputs):\n",
    "    detections = inputs[\"input-detections\"]\n",
    "    threshold = int(inputs[\"input-threshold\"])\n",
    "    comparator = inputs[\"input-comparator\"]\n",
    "    \n",
    "    count = len(detections)\n",
    "    print(f'ejecutado count_node con {count} detecciones, comparador {comparator}, threshold {threshold}')\n",
    "    \n",
    "    if comparator == \">\":\n",
    "        if count > threshold:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": True}\n",
    "        else:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": False}\n",
    "\n",
    "    elif comparator == \"<\":\n",
    "        if  count < threshold:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": True}\n",
    "        else:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": False}\n",
    "    elif comparator == \">=\":\n",
    "        if count >= threshold:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": True}\n",
    "        else:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": False}\n",
    "    elif comparator == \"<=\":\n",
    "        if count <= threshold:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": True}\n",
    "        else:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": False}\n",
    "    else:  # \"==\"\n",
    "        if count == threshold:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": True}\n",
    "        else:\n",
    "            return {\"output-alarm-trigger\": detections, \"trigger-type\": False}\n",
    "\n",
    "def camera_node(inputs):\n",
    "    camera_name = inputs[\"input-camera-name\"]\n",
    "    print(f'ejecutado camera_node con camera: {camera_name}')\n",
    "    return {'output-image-name':camera_name}\n",
    "\n",
    "def distance_node(inputs):\n",
    "    distance_threshold = inputs.get(\"distance-threshold\", 2.0)\n",
    "    print(f'ejecutado distance_node con threshold: {distance_threshold}')\n",
    "    return f\"Output of distance_node with threshold={distance_threshold}\"\n",
    "\n",
    "def start_cycle_node(inputs):\n",
    "    print('ejecutado start_cycle_node')\n",
    "    return True\n",
    "\n",
    "def notification_off_site(inputs):\n",
    "    notification_type = inputs[\"notification-type\"]\n",
    "    telegram_phone = inputs[\"telegram-phone\"]\n",
    "    telegram_message = inputs[\"telegram-message\"]\n",
    "    telegram_image = inputs[\"telegram-image\"]\n",
    "    \n",
    "    print(f'ejecutado notification_off_site con tipo: {notification_type}, telefono: {telegram_phone}')\n",
    "    return f\"Output of notification_off_site with type={notification_type}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_dag(json_path: str, plot: bool = False):\n",
    "    with open(json_path, 'r') as f:\n",
    "        flow = json.load(f)\n",
    "    # Crear el grafo\n",
    "    dag = nx.DiGraph()\n",
    "\n",
    "    # Almacenar las funciones disponibles\n",
    "    functions = {\n",
    "        \"alarm-manager\": alarm_manager,\n",
    "        \"notification-on-site\": notification_on_site,\n",
    "        \"filter-node\": filter_node,\n",
    "        \"ai-node\": ai_node,\n",
    "        \"count-node\": count_node,\n",
    "        \"camera-node\": camera_node,\n",
    "        \"notification-off-site\": notification_off_site,\n",
    "        \"start-cycle-node\": start_cycle_node,\n",
    "        \"distance-node\": distance_node\n",
    "    }\n",
    "\n",
    "    for block in flow:\n",
    "        node_id = block['id']\n",
    "        func_name = block['schemaId']  # El nombre de la función está en 'schemaId'\n",
    "        func = functions.get(func_name)\n",
    "        outputs = block.get('outputs', [])\n",
    "        if not func:\n",
    "            raise ValueError(f\"Función {func_name} no definida en el mapa de funciones\")\n",
    "        inputs = {inp['inputId']: inp['value'] for inp in block.get('inputs', [])}\n",
    "        outputs = {output['outputId']: None for output in outputs}\n",
    "        connected_inputs = {input['targetHandle']['nodeId']: {'source':input['source'], 'node_output': input['sourceHandle']['nodeId']} for input in block.get('connectedTo', {}).get('inputs', [])}\n",
    "        # Agregar el nodo al DAG\n",
    "        dag.add_node(node_id, \n",
    "                     func=func,\n",
    "                     schemaId=func_name,\n",
    "                     inputs=inputs,\n",
    "                     outputs=outputs,\n",
    "                     connected_inputs=connected_inputs)\n",
    "        print('func_name', func_name, '\\n \\n inputs', inputs, '\\n \\n outputs', outputs, '\\n \\n conected_inputs: ', connected_inputs)\n",
    "        print('mmmmmmmmmmmmmmmmmmmmm')\n",
    "        # Agregar conexiones desde los nodos de entrada\n",
    "        for connection in block.get('connectedTo', {}).get('inputs', []):\n",
    "            source_node = connection['source']\n",
    "            dag.add_edge(source_node, node_id)\n",
    "\n",
    "        # Agregar conexiones hacia los nodos de salida\n",
    "        for connection in block.get('connectedTo', {}).get('outputs', []):\n",
    "            target_node = connection['target']\n",
    "            dag.add_edge(node_id, target_node)\n",
    "\n",
    "    # Verificar que sea un DAG válido\n",
    "    if not nx.is_directed_acyclic_graph(dag):\n",
    "        raise ValueError(\"El flujo no es un DAG válido\")\n",
    "    if plot:\n",
    "        plot_dag(dag)\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_JSON = \"flows/workflow_edit.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func_name alarm-manager \n",
      " \n",
      " inputs {'alarm-selection': 'alarma_fuego', 'cooldown': '3', 'sensitivity': '23'} \n",
      " \n",
      " outputs {} \n",
      " \n",
      " conected_inputs:  {'alarm-selection': {'source': 'WVOSg_nGK-pNCveO409pC', 'node_output': 'output-alarm-trigger'}}\n",
      "mmmmmmmmmmmmmmmmmmmmm\n",
      "func_name filter-node \n",
      " \n",
      " inputs {'input-detections': 'ai-node-3-camera_detections', 'input-filter-type': 'clase', 'input-operator': '==', 'input-value': 'person'} \n",
      " \n",
      " outputs {'output-filtered-detections-pass': None, 'output-filtered-detections-fail': None} \n",
      " \n",
      " conected_inputs:  {'input-detections': {'source': 'HmqswRo8MT9u3sDogYiiC', 'node_output': 'camera_detections'}}\n",
      "mmmmmmmmmmmmmmmmmmmmm\n",
      "func_name ai-node \n",
      " \n",
      " inputs {'camera-name': 'camera-node-2-output-image-name'} \n",
      " \n",
      " outputs {'camera_detections': None} \n",
      " \n",
      " conected_inputs:  {'camera-name': {'source': 'yhtLPhFYEDOkfObJlH9L7', 'node_output': 'output-image-name'}}\n",
      "mmmmmmmmmmmmmmmmmmmmm\n",
      "func_name notification-off-site \n",
      " \n",
      " inputs {'notification-type': 'safe', 'telegram-phone': '605441602', 'telegram-message': 'alertaaaaaaa', 'telegram-image': 'imagen_1'} \n",
      " \n",
      " outputs {} \n",
      " \n",
      " conected_inputs:  {'notification-type': {'source': '18uQmbgHK_bSJeoOk4t-N', 'node_output': '18uQmbgHK_bSJeoOk4t-N-output-1'}}\n",
      "mmmmmmmmmmmmmmmmmmmmm\n",
      "func_name count-node \n",
      " \n",
      " inputs {'input-detections': '', 'input-comparator': '>', 'input-threshold': '0'} \n",
      " \n",
      " outputs {'output-alarm-trigger': None} \n",
      " \n",
      " conected_inputs:  {'input-1': {'source': '1X5AYvGcQ6IscN7g1QQMI', 'node_output': 'output-filtered-detections-pass'}}\n",
      "mmmmmmmmmmmmmmmmmmmmm\n",
      "func_name camera-node \n",
      " \n",
      " inputs {'input-camera-name': 'almacen2'} \n",
      " \n",
      " outputs {'output-image-name': None} \n",
      " \n",
      " conected_inputs:  {}\n",
      "mmmmmmmmmmmmmmmmmmmmm\n"
     ]
    }
   ],
   "source": [
    "my_dag = build_dag(FILE_JSON, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_degrees = dict(my_dag.in_degree())\n",
    "# ready_nodes = [node for node, degree in in_degrees.items() if degree == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_inputs(my_dag, node_id):\n",
    "    node_data = my_dag.nodes[node_id]\n",
    "    connected_inputs = node_data['connected_inputs']\n",
    "    inputs = node_data['inputs']\n",
    "    for k, connected_input in connected_inputs.items():\n",
    "        if k not in inputs.keys():\n",
    "            continue\n",
    "        source_node = connected_input['source']\n",
    "        source_output = connected_input['node_output']\n",
    "        antecesor_node_data = my_dag.nodes[source_node]\n",
    "        print('k', k)\n",
    "        print('source_node', source_node)\n",
    "        print('source_output',source_output)\n",
    "        print(\"antecesor_node_data['outputs']\", antecesor_node_data['outputs'])\n",
    "        output_value = antecesor_node_data['outputs'][source_output]\n",
    "        inputs[k] = output_value\n",
    "    return inputs\n",
    "\n",
    "def update_outputs(my_dag, node_id, results):\n",
    "    node_data = my_dag.nodes[node_id]\n",
    "    outputs = node_data['outputs']\n",
    "    print(results)\n",
    "    for k, output in outputs.items():\n",
    "        outputs[k] = results[k]\n",
    "        print('outputs actualizados', outputs)\n",
    "    return my_dag\n",
    "\n",
    "def process_node(my_dag, node_id):\n",
    "    \"\"\"\n",
    "    Procesa un nodo ejecutando su función con todos sus inputs\n",
    "    \"\"\"\n",
    "    print('--------------------------------')\n",
    "    node_data = my_dag.nodes[node_id]\n",
    "    func = node_data['func']\n",
    "\n",
    "    print(f\"Function name: {func.__name__}\")\n",
    "    inputs = get_node_inputs(my_dag, node_id)\n",
    "\n",
    "    print(f\"All inputs: {inputs}\")\n",
    "    \n",
    "    # time.sleep(0.5)\n",
    "    \n",
    "    # # Ejecutar la función con el diccionario de inputs\n",
    "    results = func(inputs=inputs)\n",
    "    # print(f'Results for {node_id}:', results)\n",
    "    my_dag = update_outputs(my_dag, node_id, results)\n",
    "    # print(f'Results for {node_id}:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Function name: camera_node\n",
      "All inputs: {'input-camera-name': 'almacen2'}\n",
      "ejecutado camera_node con camera: almacen2\n",
      "{'output-image-name': 'almacen2'}\n",
      "outputs actualizados {'output-image-name': 'almacen2'}\n",
      "--------------------------------\n",
      "Function name: ai_node\n",
      "k camera-name\n",
      "source_node yhtLPhFYEDOkfObJlH9L7\n",
      "source_output output-image-name\n",
      "antecesor_node_data['outputs'] {'output-image-name': 'almacen2'}\n",
      "All inputs: {'camera-name': 'almacen2'}\n",
      "ejecutado ai_node para camara: almacen2\n",
      "{'camera_detections': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'perro', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'coche', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}]}\n",
      "outputs actualizados {'camera_detections': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'perro', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'coche', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}]}\n",
      "--------------------------------\n",
      "Function name: filter_node\n",
      "k input-detections\n",
      "source_node HmqswRo8MT9u3sDogYiiC\n",
      "source_output camera_detections\n",
      "antecesor_node_data['outputs'] {'camera_detections': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'perro', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'coche', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}]}\n",
      "All inputs: {'input-detections': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'perro', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'coche', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}], 'input-filter-type': 'clase', 'input-operator': '==', 'input-value': 'person'}\n",
      "ejecutado filter_node con tipo: clase, operador: ==, valor: person\n",
      "{'output-filtered-detections-pass': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}], 'output-filtered-detections-fail': [{'object': 'perro', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'coche', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}]}\n",
      "outputs actualizados {'output-filtered-detections-pass': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}], 'output-filtered-detections-fail': None}\n",
      "outputs actualizados {'output-filtered-detections-pass': [{'object': 'person', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}], 'output-filtered-detections-fail': [{'object': 'perro', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}, {'object': 'coche', 'confidence': 0.9171023964881897, 'id_tracking': 7, 'bbox': [0.5441161394119263, 0.5410915017127991, 0.6872852444648743, 0.9145181179046631], 'keypoints': None, 'contours': None, 'coord': [-7.224, 40.07], 'speed': [0.3586715, -12.65756]}]}\n",
      "--------------------------------\n",
      "Function name: count_node\n",
      "All inputs: {'input-detections': '', 'input-comparator': '>', 'input-threshold': '0'}\n",
      "ejecutado count_node con 0 detecciones, comparador >, threshold 0\n",
      "{'output-alarm-trigger': '', 'trigger-type': False}\n",
      "outputs actualizados {'output-alarm-trigger': ''}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# node_data = my_dag.nodes['yhtLPhFYEDOkfObJlH9L7']\n",
    "# print(node_data)\n",
    "\n",
    "# node_data = my_dag.nodes['FyyVHNJZeLUMIH3Es-h_k']\n",
    "# print(node_data)\n",
    "\n",
    "# node_data = my_dag.nodes['HmqswRo8MT9u3sDogYiiC']\n",
    "# print(node_data)\n",
    "# process_node(my_dag, 'FyyVHNJZeLUMIH3Es-h_k')\n",
    "process_node(my_dag, \"yhtLPhFYEDOkfObJlH9L7\")\n",
    "process_node(my_dag, \"HmqswRo8MT9u3sDogYiiC\")\n",
    "process_node(my_dag, \"1X5AYvGcQ6IscN7g1QQMI\")\n",
    "process_node(my_dag, \"WVOSg_nGK-pNCveO409pC\")\n",
    "# process_node(my_dag, \"18uQmbgHK_bSJeoOk4t-N\")\n",
    "# process_node(my_dag, \"LGGNrUGwfH0hBALCp5lop\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_degrees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Crear un ejecutor para manejar la concurrencia\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Inicializar la cola con nodos sin predecesores\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     ready_nodes \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node, degree \u001b[38;5;129;01min\u001b[39;00m \u001b[43min_degrees\u001b[49m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m degree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     63\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m ready_nodes \u001b[38;5;129;01mor\u001b[39;00m futures:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;66;03m# Lanzar tareas para nodos listos\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in_degrees' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_node_inputs(node_id, node_data):\n",
    "    \"\"\"\n",
    "    Obtiene todos los inputs del nodo, tanto valores directos como conexiones\n",
    "    \"\"\"\n",
    "    # Crear diccionario con los valores directos de los inputs\n",
    "    # input_values = {\n",
    "    #     inp['inputId']: inp['value'] \n",
    "    #     for inp in node_data.get('inputs', [])\n",
    "    # }\n",
    "    print('input_values', node_data['params'])\n",
    "    # Buscar conexiones de entrada y actualizar valores\n",
    "    for predecessor in my_dag.predecessors(node_id):\n",
    "        pred_data = my_dag.nodes[predecessor]\n",
    "        connections = [\n",
    "            conn for conn in pred_data.get('connectedTo', {}).get('outputs', [])\n",
    "            if conn['target'] == node_id\n",
    "        ]\n",
    "        \n",
    "        for connection in connections:\n",
    "            source_node = connection['source']\n",
    "            source_handle = connection['sourceHandle']['nodeId']\n",
    "            target_handle = connection['targetHandle']['nodeId']\n",
    "            \n",
    "            if source_node in results:\n",
    "                # Manejar múltiples outputs (como en filter_node)\n",
    "                if isinstance(results[source_node], tuple):\n",
    "                    if source_handle == 'output-filtered-detections-pass':\n",
    "                        input_values[target_handle] = results[source_node][0]\n",
    "                    elif source_handle == 'output-filtered-detections-fail':\n",
    "                        input_values[target_handle] = results[source_node][1]\n",
    "                else:\n",
    "                    input_values[target_handle] = results[source_node]\n",
    "    \n",
    "    return input_values\n",
    "\n",
    "def process_node(node_id):\n",
    "    \"\"\"\n",
    "    Procesa un nodo ejecutando su función con todos sus inputs\n",
    "    \"\"\"\n",
    "    node_data = my_dag.nodes[node_id]\n",
    "    func = node_data['func']\n",
    "    # inputs = node_data['params']\n",
    "    print(node_data['outputs'])\n",
    "    # Obtener todos los inputs como un diccionario\n",
    "    \n",
    "\n",
    "    \n",
    "    inputs = get_node_inputs(node_id, node_data)\n",
    "    print('--------------------------------')\n",
    "    print(f\"Function name: {func.__name__}\")\n",
    "    print(f\"All inputs: {inputs}\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # Ejecutar la función con el diccionario de inputs\n",
    "    results[node_id] = func(inputs=inputs)\n",
    "    print(f'Results for {node_id}:', results[node_id])\n",
    "\n",
    "# Crear un ejecutor para manejar la concurrencia\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Inicializar la cola con nodos sin predecesores\n",
    "    ready_nodes = [node for node, degree in in_degrees.items() if degree == 0]\n",
    "    futures = {}\n",
    "\n",
    "    while ready_nodes or futures:\n",
    "        # Lanzar tareas para nodos listos\n",
    "        for node_id in ready_nodes:\n",
    "            futures[node_id] = executor.submit(process_node, node_id)\n",
    "\n",
    "        ready_nodes = []\n",
    "\n",
    "        # Esperar a que se completen algunas tareas\n",
    "        for node_id, future in list(futures.items()):\n",
    "            if future.done():\n",
    "                future.result()  # Propagar excepciones si ocurrieron\n",
    "                futures.pop(node_id)\n",
    "\n",
    "                # Reducir el in-degree de los sucesores y agregar a la lista de listos\n",
    "                for successor in my_dag.successors(node_id):\n",
    "                    in_degrees[successor] -= 1\n",
    "                    if in_degrees[successor] == 0:\n",
    "                        ready_nodes.append(successor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
